{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.ml.stat as ml_stat\n",
    "import pyspark.sql.functions as func\n",
    "import pyspark.sql.types as types\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Spark Test App').getOrCreate() \n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "|18.0|        8|       307.0|       130|  3504|        12.0|  70|     1|chevrolet chevell...|\n",
      "|15.0|        8|       350.0|       165|  3693|        11.5|  70|     1|   buick skylark 320|\n",
      "|18.0|        8|       318.0|       150|  3436|        11.0|  70|     1|  plymouth satellite|\n",
      "|16.0|        8|       304.0|       150|  3433|        12.0|  70|     1|       amc rebel sst|\n",
      "|17.0|        8|       302.0|       140|  3449|        10.5|  70|     1|         ford torino|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Data Frame from a csv file with inferred schema\n",
    "df_auto = spark.read.csv('Auto.csv', header=True, inferSchema=True)\n",
    "df_auto.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|      date|           timestamp|\n",
      "+---+----------+--------------------+\n",
      "|  0|2020-06-20|2020-06-20 14:08:...|\n",
      "|  1|2020-06-20|2020-06-20 14:08:...|\n",
      "|  2|2020-06-20|2020-06-20 14:08:...|\n",
      "|  3|2020-06-20|2020-06-20 14:08:...|\n",
      "|  4|2020-06-20|2020-06-20 14:08:...|\n",
      "+---+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Current date and time\n",
    "df = spark.range(10) \\\n",
    "    .withColumn('date', func.current_date()) \\\n",
    "    .withColumn('timestamp', func.current_timestamp())\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+----------+----------+\n",
      "| id|      date|           timestamp|  tomorrow| yesterday|\n",
      "+---+----------+--------------------+----------+----------+\n",
      "|  0|2020-06-20|2020-06-20 14:08:...|2020-06-21|2020-06-19|\n",
      "|  1|2020-06-20|2020-06-20 14:08:...|2020-06-21|2020-06-19|\n",
      "|  2|2020-06-20|2020-06-20 14:08:...|2020-06-21|2020-06-19|\n",
      "|  3|2020-06-20|2020-06-20 14:08:...|2020-06-21|2020-06-19|\n",
      "|  4|2020-06-20|2020-06-20 14:08:...|2020-06-21|2020-06-19|\n",
      "+---+----------+--------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding and subtracting dates\n",
    "df.withColumn('tomorrow', func.date_add('date', 1)) \\\n",
    "    .withColumn('yesterday', func.date_add('date', -1)) \\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+----------------+\n",
      "| id|      date|           timestamp|date_from_string|\n",
      "+---+----------+--------------------+----------------+\n",
      "|  0|2020-06-20|2020-06-20 14:08:...|      2020-06-01|\n",
      "|  1|2020-06-20|2020-06-20 14:08:...|      2020-06-01|\n",
      "|  2|2020-06-20|2020-06-20 14:08:...|      2020-06-01|\n",
      "|  3|2020-06-20|2020-06-20 14:08:...|      2020-06-01|\n",
      "|  4|2020-06-20|2020-06-20 14:08:...|      2020-06-01|\n",
      "+---+----------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Date from string of the form yyyy-mm-dd (in sql)\n",
    "df.withColumn('date_from_string', func.expr(\"cast('2020-06-01' as date)\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- date: date (nullable = false)\n",
      " |-- timestamp: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_auto.withColumn('horsepower', func.expr('cast(horsepower as float)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "|25.0|        4|        98.0|      null|  2046|        19.0|  71|     1|          ford pinto|\n",
      "|21.0|        6|       200.0|      null|  2875|        17.0|  74|     1|       ford maverick|\n",
      "|40.9|        4|        85.0|      null|  1835|        17.3|  80|     2|renault lecar deluxe|\n",
      "|23.6|        4|       140.0|      null|  2905|        14.3|  80|     1|  ford mustang cobra|\n",
      "|34.5|        4|       100.0|      null|  2320|        15.8|  81|     2|         renault 18i|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where('horsepower is null').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where any columns has a null value\n",
    "df.dropna('any').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where all columns are null\n",
    "df.dropna('all').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows where certain columns are null\n",
    "df.dropna('all', subset=['horsepower', 'name']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "| mpg|cylinders|displacement|horsepower|weight|acceleration|year|origin|                name|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "|25.0|        4|        98.0|       0.0|  2046|        19.0|  71|     1|          ford pinto|\n",
      "|21.0|        6|       200.0|       0.0|  2875|        17.0|  74|     1|       ford maverick|\n",
      "|40.9|        4|        85.0|       0.0|  1835|        17.3|  80|     2|renault lecar deluxe|\n",
      "|23.6|        4|       140.0|       0.0|  2905|        14.3|  80|     1|  ford mustang cobra|\n",
      "|34.5|        4|       100.0|       0.0|  2320|        15.8|  81|     2|         renault 18i|\n",
      "+----+---------+------------+----------+------+------------+----+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill with column defaults\n",
    "col_defaults = {\n",
    "    'cylinders': 4,\n",
    "    'horsepower': 0\n",
    "}\n",
    "df.fillna(col_defaults).where('horsepower == 0').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Type: Struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structs are like DataFrames within DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                name|       data|\n",
      "+--------------------+-----------+\n",
      "|chevrolet chevell...|[18.0, 130]|\n",
      "|   buick skylark 320|[15.0, 165]|\n",
      "|  plymouth satellite|[18.0, 150]|\n",
      "|       amc rebel sst|[16.0, 150]|\n",
      "|         ford torino|[17.0, 140]|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create struct of mpg and horsepower\n",
    "df_auto.select('name', func.struct('mpg', 'horsepower').alias('data')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                name|       data|\n",
      "+--------------------+-----------+\n",
      "|chevrolet chevell...|[18.0, 130]|\n",
      "|   buick skylark 320|[15.0, 165]|\n",
      "|  plymouth satellite|[18.0, 150]|\n",
      "|       amc rebel sst|[16.0, 150]|\n",
      "|         ford torino|[17.0, 140]|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create struct in sql with ()\n",
    "df = df_auto.selectExpr('name', '(mpg, horsepower) as data')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|                name| mpg|\n",
      "+--------------------+----+\n",
      "|chevrolet chevell...|18.0|\n",
      "|   buick skylark 320|15.0|\n",
      "|  plymouth satellite|18.0|\n",
      "|       amc rebel sst|16.0|\n",
      "|         ford torino|17.0|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select from struct\n",
    "df.select('name', 'data.mpg').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Type: Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| Name|          Competence|\n",
      "+-----+--------------------+\n",
      "|  Joe|Python, Spark, Kafka|\n",
      "|Henry|React, Redux, Jav...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "df = spark.createDataFrame([\n",
    "    ('Joe', 'Python, Spark, Kafka'),\n",
    "    ('Henry', 'React, Redux, JavaScript')],\n",
    "    ['Name', 'Competence']\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "| Name|          Competence|\n",
      "+-----+--------------------+\n",
      "|  Joe|[Python,  Spark, ...|\n",
      "|Henry|[React,  Redux,  ...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split field and gather in array\n",
    "df = df.selectExpr(\"Name\", \"split(Competence, ',') as Competence\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Competence: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "| Name|Competence[0]|\n",
      "+-----+-------------+\n",
      "|  Joe|       Python|\n",
      "|Henry|        React|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select array item\n",
    "df.selectExpr(\"Name\", \"Competence[0]\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Competence: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| Name|Python_Dev|\n",
      "+-----+----------+\n",
      "|  Joe|      true|\n",
      "|Henry|     false|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if array contains item\n",
    "df.selectExpr(\"Name\", \"array_contains(Competence, 'Python') as Python_Dev\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| Name|Python_Dev|\n",
      "+-----+----------+\n",
      "|  Joe|      true|\n",
      "|Henry|     false|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same\n",
    "df.select(\"Name\", func.array_contains(\"Competence\", \"Python\").alias(\"Python_Dev\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| Name|Competence|\n",
      "+-----+----------+\n",
      "|  Joe|    Python|\n",
      "|  Joe|     Spark|\n",
      "|  Joe|     Kafka|\n",
      "|Henry|     React|\n",
      "|Henry|     Redux|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode Array into multiple rows\n",
    "df.withColumn('Competence', func.explode('Competence')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Types: Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                name|        data|\n",
      "+--------------------+------------+\n",
      "|chevrolet chevell...|[70 -> 18.0]|\n",
      "|   buick skylark 320|[70 -> 15.0]|\n",
      "|  plymouth satellite|[70 -> 18.0]|\n",
      "|       amc rebel sst|[70 -> 16.0]|\n",
      "|         ford torino|[70 -> 17.0]|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create map in sql\n",
    "df = df_auto.selectExpr('name', 'map(year, mpg) as data')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         json_string|\n",
      "+--------------------+\n",
      "|{\"prop1\": \"value1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create column with JSON datatype\n",
    "df = spark.range(1).selectExpr(\"\"\"\n",
    "    '{\"prop1\": \"value1\", \"prop2\": [1, 2, 3]}' as json_string\n",
    "\"\"\");\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select value from json\n",
    "df.select(func.get_json_object('json_string', '$.prop2[0]').alias('value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select value from json (SQL like syntax)\n",
    "df.selectExpr(\"get_json_object(json_string, '$.prop2[0]') as value\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----------+\n",
      "|               items|         kind|totalItems|\n",
      "+--------------------+-------------+----------+\n",
      "|[[[SAMPLE, DE, tr...|books#volumes|       334|\n",
      "+--------------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read json \n",
    "df=spark.read.json(\"python_books.json\", multiLine=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               items|\n",
      "+--------------------+\n",
      "|[[[Python Program...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read json selectively with schema\n",
    "schema=types.StructType([\n",
    "    types.StructField(\"items\", types.ArrayType(types.StructType([\n",
    "        types.StructField(\"volumeInfo\", types.StructType([\n",
    "            types.StructField(\"title\", types.StringType())\n",
    "        ]))\n",
    "    ])\n",
    "    ))\n",
    "])\n",
    "\n",
    "df=spark.read.json(\"python_books.json\", schema=schema, multiLine=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               items|\n",
      "+--------------------+\n",
      "|[[[Python Program...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More convenient way to define a schema with add method on StructType\n",
    "schema = (types.StructType()\n",
    "            .add(\"items\", types.ArrayType(types.StructType()\n",
    "                   .add(\"volumeInfo\", types.StructType()\n",
    "                           .add(\"title\", types.StringType())\n",
    "                       )\n",
    "                ))\n",
    "         )\n",
    "\n",
    "df=spark.read.json(\"python_books.json\", schema=schema, multiLine=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               items|\n",
      "+--------------------+\n",
      "|[[Python Programm...|\n",
      "|[[Core Python Pro...|\n",
      "|[[Python for Begi...|\n",
      "|[[Python Programm...|\n",
      "|[[Programming Pyt...|\n",
      "|[[Learn Python Pr...|\n",
      "|[[Expert Python P...|\n",
      "|[[Python Programm...|\n",
      "|[[Python Programm...|\n",
      "|[[Python Programm...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.select(func.explode(\"items\").alias(\"items\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- items: struct (nullable = true)\n",
      " |    |-- volumeInfo: struct (nullable = true)\n",
      " |    |    |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|  Python Programming|\n",
      "|Core Python Progr...|\n",
      "|Python for Beginners|\n",
      "|Python Programmin...|\n",
      "|  Programming Python|\n",
      "|Learn Python Prog...|\n",
      "|Expert Python Pro...|\n",
      "|Python Programmin...|\n",
      "|Python Programmin...|\n",
      "|Python Programmin...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List book titles\n",
    "df2.select(\"items.volumeInfo.title\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
